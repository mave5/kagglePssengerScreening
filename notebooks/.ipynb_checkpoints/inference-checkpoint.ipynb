{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu0,floatX=float32\" \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import h5py\n",
    "#import models\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import datetime\n",
    "\n",
    "#import pandas as pd\n",
    "import glob\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "import datetime\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "# get package versions\n",
    "def get_version(*vars):\n",
    "    for var in vars:\n",
    "        module = __import__(var)    \n",
    "        print ('%s: %s' %(var,module.__version__))\n",
    "    \n",
    "# package version    \n",
    "get_version('keras','numpy','matplotlib','cv2','theano')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# normalization \n",
    "#norm_type='minus1plus1'\n",
    "norm_type='zeroMeanUnitVar'\n",
    "\n",
    "# data folder\n",
    "path2data='../data/'\n",
    "\n",
    "# stage 1 training data\n",
    "path2stage1_train=path2data+'stage1_train.hdf5'\n",
    "\n",
    "# stage 1 test data\n",
    "path2stage1_test=path2data+'stage1_test.hdf5'\n",
    "\n",
    "# stage 1 sample submission\n",
    "path2stage1submission = path2data+'stage1_sample_submission.csv'\n",
    "path2_stage1_labels=path2data+\"stage1_labels.csv\"\n",
    "path2_stage1_solution=path2data+\"stage1_solution.csv\"\n",
    "\n",
    "# stage 2 sample submission\n",
    "path2stage2submission = path2data+'stage2_sample_submission.csv'\n",
    "\n",
    "# zone orders in the csv file are like this\n",
    "zones=['zone1','zone10','zone11','zone12',\n",
    "       'zone13','zone14','zone15','zone16',\n",
    "       'zone17','zone2','zone3','zone4',\n",
    "       'zone5','zone6','zone7','zone8','zone9']\n",
    "\n",
    "body_zone_desc={\n",
    "        'zone1' :'Right Bicep',\n",
    "        'zone10':'Upper left Hip/thigh',\n",
    "        'zone11':'Lowe Right Thigh',\n",
    "        'zone12':'Lower left Thigh',\n",
    "        'zone13':'Right Calf',\n",
    "        'zone14':'Left Calf(below knee)',\n",
    "        'zone15':'Right Ankle Bone',\n",
    "        'zone16':'Left Ankle Bone',\n",
    "        'zone17':'Upper Back',    \n",
    "        'zone2':'Right Forearm',\n",
    "        'zone3':'Left Bicep',\n",
    "        'zone4':'Left Forearm',\n",
    "        'zone5':'Upper Chest',\n",
    "        'zone6':'Right Rib Cage and Abs',\n",
    "        'zone7':'Left Side Rib Cage and Abs',\n",
    "        'zone8':'Upper Right Hip/Tigh',\n",
    "        'zone9':'Groin (Sensetive area)'\n",
    "        } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def array_stats(X):\n",
    "    X=np.asarray(X)\n",
    "    print ('array shape: ',X.shape, X.dtype)\n",
    "    #print 'min: %.3f, max:%.3f, avg: %.3f, std:%.3f' %(np.min(X),np.max(X),np.mean(X),np.std(X))\n",
    "    print ('min: {}, max: {}, avg: {:.3}, std:{:.3}'.format( np.min(X),np.max(X),np.mean(X),np.std(X)))\n",
    "\n",
    "def preprocess(X,xnormType=None):\n",
    "    if xnormType=='minus1plus1':\n",
    "        X=X.astype('float32')\n",
    "        X/=np.max(X)\n",
    "        X-=0.5\n",
    "        X=X*2\n",
    "    elif xnormType=='zeroMeanUnitVar':\n",
    "        X=X.astype('float32')\n",
    "        X-=np.mean(X)\n",
    "        stdX=np.std(X)\n",
    "        if stdX>0.0:\n",
    "            X/=stdX\n",
    "    else:\n",
    "        print('no normalization type found!!')\n",
    "        pass\n",
    "        \n",
    "    return X\n",
    "    \n",
    "def logloss(y_true,y_pred):\n",
    "    sumY=[]\n",
    "    n1,n2=y_true.shape\n",
    "    for i1 in range(n1):\n",
    "        for i2 in range(n2):\n",
    "            yi=y_true[i1,i2]\n",
    "            yih=y_pred[i1,i2]\n",
    "            # clip outputs\n",
    "            yi=max(min(yi,1-10**(-15)),10**(-15))\n",
    "            yih=max(min(yih,1-10**(-15)),10**(-15))\n",
    "            \n",
    "            # calculate log loss\n",
    "            p1=yi*np.log(yih)+(1-yi)*np.log(1-yih)\n",
    "            sumY.append(p1)\n",
    "    return -np.mean(sumY)\n",
    "\n",
    "def getPath2data4model(path2model,data_type=\"\",path2data=\"\"):\n",
    "    sub=os.path.basename(path2model)\n",
    "    if \"512\" in sub and \"660\" in sub:\n",
    "        h,w=512,660\n",
    "    else:    \n",
    "        h,w=256,330\n",
    "    \n",
    "    if \"Rotate90\" in sub:\n",
    "        data_type=data_type+\"90\"\n",
    "    elif \"Rotate180\" in sub:\n",
    "        data_type=data_type+\"180\"\n",
    "    elif \"Rotate270\" in sub:\n",
    "        data_type=data_type+\"270\"\n",
    "        \n",
    "    path2data4model=path2data+data_type+'_'+str(h)+'by'+str(w)+'.hdf5'\n",
    "    print (path2data4model)                \n",
    "\n",
    "    return path2data4model\n",
    "\n",
    "# fix optimization error in keras models\n",
    "def fix_files_in_folder_and_subfolders(path):\n",
    "    print \"Deleting optimizer weights from:\"\n",
    "    for item in os.listdir(path):\n",
    "        if item.lower().endswith((\".hdf5\",)) or item.lower().endswith((\".h5\",)):\n",
    "            model_file = os.path.join(path, item)\n",
    "            print model_file\n",
    "            with h5py.File(model_file, 'a') as f:\n",
    "                if 'optimizer_weights' in f.keys():\n",
    "                    print model_file\n",
    "                    del f['optimizer_weights']\n",
    "        else:\n",
    "            subpath = os.path.join(path, item)\n",
    "            if os.path.isdir(subpath):\n",
    "                fix_files_in_folder_and_subfolders(subpath)\n",
    "\n",
    "\n",
    "# display a sample subject\n",
    "def dispSampleSubject(X,y_zone=None): \n",
    "    # X shape: N*C*H*W\n",
    "    sbj_num=np.random.randint(len(X))\n",
    "    print ('subject: %s' %sbj_num)\n",
    "    #array_stats(X[sbj_num])\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    for k in range(16):\n",
    "        plt.subplot(4,4,k+1)\n",
    "        plt.imshow(X[sbj_num,k],cmap='gray')\n",
    "    if y_zone is not None:\n",
    "        # zones with objects\n",
    "        nz_label=np.nonzero(y_zone[sbj_num,:])[0]\n",
    "        for nz_l in nz_label:\n",
    "            print ('%s: %s' %(zones[nz_l],body_zone_desc[zones[nz_l]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fetching list of models/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# weights \n",
    "path2weights='./output/weights/'\n",
    "\n",
    "# sort by time\n",
    "weightList = os.listdir(path2weights)\n",
    "weightList.sort(key=lambda x: os.path.getmtime(path2weights+x))\n",
    "\n",
    "for i,sub in enumerate(weightList):\n",
    "    print ('%s- %s \\n' %(i,os.path.basename(sub)))\n",
    "    try:\n",
    "        path2model=glob.glob(path2weights+sub+'/*.h5')[0]\n",
    "    except:\n",
    "        print('there is no h5 file!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix optimization error in keras models if needed\n",
    "#fix_files_in_folder_and_subfolders(path2weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on stage1 leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "# normalization \n",
    "norm_type='zeroMeanUnitVar'\n",
    "\n",
    "# number of zones \n",
    "nb_zones=17\n",
    "\n",
    "# read stage 1 leaderboard labels\n",
    "stage1_test=pd.read_csv(path2_stage1_solution)\n",
    "Probability=stage1_test.Probability\n",
    "y_zone1=np.array(Probability)\n",
    "y_stage1=np.reshape(y_zone1,(len(y_zone1)/nb_zones,nb_zones))\n",
    "print ('labels shape:', y_stage1.shape)\n",
    "\n",
    "# specify what data \n",
    "data_type=\"stage1_leader\"\n",
    "\n",
    "yPreds=[]\n",
    "for wn,sub in enumerate(weightList):\n",
    "\n",
    "    # get path to correct data for a model\n",
    "    path2_stage1leader=getPath2data4model(sub,data_type,path2data)    \n",
    "    \n",
    "    # load leaderborad data\n",
    "    try:\n",
    "        ff_stage1leader=h5py.File(path2_stage1leader,'r')\n",
    "        ids_stage1leader=ff_stage1leader['ids'].value\n",
    "        X_stage1leader=ff_stage1leader['X'].value\n",
    "        array_stats(X_stage1leader)\n",
    "        #dispSampleSubject(X_stage1leader,y_stage1)\n",
    "   \n",
    "        print ('%s- %s \\n' %(wn,os.path.basename(sub)))\n",
    "        path2model=glob.glob(path2weights+sub+'/*.h5')[0]\n",
    "        model=load_model(path2model)\n",
    "        #model.summary()\n",
    "        print('wait ...')\n",
    "        try:\n",
    "            #score_test=model.evaluate(preprocess(X_stage1leader,norm_type)[:,:,np.newaxis],y_stage1,verbose=0,batch_size=8)\n",
    "            yPredPerModel=model.predict(preprocess(X_stage1leader,norm_type)[:,:,np.newaxis],batch_size=8)\n",
    "            yPreds.append(yPredPerModel)\n",
    "            score_test=logloss(y_stage1,yPredPerModel)\n",
    "            print ('score test is %s' %(score_test))    \n",
    "        except:\n",
    "            print('could not get score test!')\n",
    "        print('-'*60)\n",
    "    except:   \n",
    "        print('could not load data!')\n",
    "        print('-'*60)\n",
    "        \n",
    "# Score test for ensemble\n",
    "y_pred1=np.array(yPreds)\n",
    "y_pred2=np.mean(y_pred1,axis=0)\n",
    "print y_pred2.shape\n",
    "scoreEnsemble=logloss(y_stage1,y_pred2)\n",
    "print('ensemble score for %s models: %s' %(len(yPreds),scoreEnsemble))\n",
    "\n",
    "r1,c1=y_pred2.shape\n",
    "#print y_pred2[0:5]\n",
    "#print (r1,c1)\n",
    "pred=np.reshape(y_pred2,(r1*c1,1))\n",
    "print (pred.shape)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference for Stage2 leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalization \n",
    "norm_type='zeroMeanUnitVar'\n",
    "\n",
    "# number of zones \n",
    "nb_zones=17\n",
    "\n",
    "# specify what data \n",
    "data_type=\"stage2_leader\"\n",
    "\n",
    "yPreds=[]\n",
    "for wn,sub in enumerate(weightList):\n",
    "\n",
    "    # get path to correct data for a model\n",
    "    path2_stagenleader=getPath2data4model(sub,data_type,path2data)    \n",
    "    \n",
    "    # load leaderborad data\n",
    "    try:\n",
    "        ff_stagenleader=h5py.File(path2_stagenleader,'r')\n",
    "        ids_stagenleader=ff_stagenleader['ids'].value\n",
    "        X_stagenleader=ff_stagenleader['X'].value\n",
    "        array_stats(X_stagenleader)\n",
    "        #dispSampleSubject(X_stagenleader)\n",
    "   \n",
    "        print ('%s- %s \\n' %(wn,os.path.basename(sub)))\n",
    "        path2model=glob.glob(path2weights+sub+'/*.h5')[0]\n",
    "        model=load_model(path2model)\n",
    "        #model.summary()\n",
    "        print('wait ...')\n",
    "        try:\n",
    "            yPredPerModel=model.predict(preprocess(X_stagenleader,norm_type)[:,:,np.newaxis],batch_size=8)\n",
    "            yPreds.append(yPredPerModel)\n",
    "            print (yPredPerModel[0])\n",
    "            print('compeleted predictions!')\n",
    "        except:\n",
    "            print('could not get score test!')\n",
    "        print('-'*60)\n",
    "    except:   \n",
    "        print('could not load data!')\n",
    "        print('-'*60)\n",
    "        \n",
    "# Score test for ensemble\n",
    "y_pred1=np.array(yPreds)\n",
    "y_pred2=np.mean(y_pred1,axis=0)\n",
    "print y_pred2.shape\n",
    "#scoreEnsemble=logloss(y_stage1,y_pred2)\n",
    "#print('ensemble score for %s models: %s' %(len(yPreds),scoreEnsemble))\n",
    "print('ensemble of %s models' %(len(yPreds)))\n",
    "\n",
    "r1,c1=y_pred2.shape\n",
    "#print y_pred2[0:5]\n",
    "#print (r1,c1)\n",
    "pred=np.reshape(y_pred2,(r1*c1,1))\n",
    "print (pred.shape)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%script false \n",
    "submission  = pd.read_csv(path2stage2submission)\n",
    "pid = submission ['Id'].values\n",
    "\n",
    "# make submission\n",
    "now = datetime.datetime.now()\n",
    "info=\"submission_ensemble11\"\n",
    "suffix = info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "path2submission = os.path.join('./output/submissions', 'submission_' + suffix + '.csv')\n",
    "\n",
    "#submission = pd.DataFrame(pred, columns=['Probability'])\n",
    "submission['Id'] = pid\n",
    "submission['Probability'] = pred\n",
    "submission.to_csv(path2submission, index=False)\n",
    "submission.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
